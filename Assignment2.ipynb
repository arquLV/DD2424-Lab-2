{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.matlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import copy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_batch(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        dataset = pickle.load(f, encoding='latin1') # Nxd(3072) (Nx (32x32x3))\n",
    "        X = np.transpose(dataset['data'] / 255.) # d x N\n",
    "        mean_X = np.mean(X, axis=1) # mean of each row (each feature mean)\n",
    "        std_X = np.std(X, axis=1)\n",
    "        X = X - np.matlib.repmat(mean_X, X.shape[1], 1).T\n",
    "        X = np.divide(X, np.matlib.repmat(std_X, X.shape[1], 1).T)\n",
    "        \n",
    "        y = np.array(dataset['labels'])\n",
    "        Y = np.transpose(np.eye(X.shape[1], np.max(y) + 1)[y]) # K x N\n",
    "        return X, Y, y\n",
    "\n",
    "def load_all(validation_size):\n",
    "    X_1, Y_1, y_1 = load_batch('data/data_batch_1')\n",
    "    X_2, Y_2, y_2 = load_batch('data/data_batch_2')\n",
    "    X_3, Y_3, y_3 = load_batch('data/data_batch_3')\n",
    "    X_4, Y_4, y_4 = load_batch('data/data_batch_4')\n",
    "    X_5, Y_5, y_5 = load_batch('data/data_batch_5')\n",
    "    \n",
    "    X = np.concatenate((X_1, X_2, X_3, X_4, X_5[:,:-validation_size]), axis=1)\n",
    "    Y = np.concatenate((Y_1, Y_2, Y_3, Y_4, Y_5[:,:-validation_size]), axis=1)\n",
    "    y = np.concatenate((y_1, y_2, y_3, y_4, y_5[:-validation_size]))\n",
    "    \n",
    "    X_valid = X_5[:,-validation_size:]\n",
    "    Y_valid = Y_5[:,-validation_size:]\n",
    "    y_valid = y_5[-validation_size:]\n",
    "    return X, Y, y, X_valid, Y_valid, y_valid\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(s):\n",
    "    exponent = np.exp(s)\n",
    "    return np.divide(exponent, np.sum(exponent, axis=0))\n",
    "\n",
    "def evaluate_classifier(X, layers):\n",
    "    num_layers = len(layers)\n",
    "    H = []\n",
    "    h_prev = X\n",
    "    \n",
    "    for i, layer in enumerate(layers):\n",
    "        if i == num_layers - 1:  # If last layer\n",
    "            P = softmax(np.dot(layer[\"W\"], h_prev) + layer[\"b\"]) # K x N\n",
    "            return H, P\n",
    "        else:\n",
    "            s = np.dot(layer[\"W\"], h_prev) + layer[\"b\"] # m x N\n",
    "            h = np.maximum(s, 0) # ReLU; m x N\n",
    "            H.append(h)\n",
    "            h_prev = h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(X, Y, layers, lmb):\n",
    "    H, P = evaluate_classifier(X, layers)\n",
    "    n = np.sum(np.multiply(Y, P), axis=0)\n",
    "    cross_entropy = np.sum(-np.log(n))\n",
    "    \n",
    "    w_square_sum = 0\n",
    "    if lmb > 0:\n",
    "        for layer in layers:\n",
    "            w_square_sum += np.sum(np.diag(np.dot(layer[\"W\"].T, layer[\"W\"])))\n",
    "    return (cross_entropy / X.shape[1]) + (lmb * w_square_sum)\n",
    "\n",
    "def compute_gradients(X, Y, layers, lmb):\n",
    "    H, P = evaluate_classifier(X, layers)\n",
    "    G = -(Y - P)\n",
    "    Nb = X.shape[1] # batch size\n",
    "    \n",
    "    W_gradients = []\n",
    "    b_gradients = []\n",
    "    for i, layer in reversed(list(enumerate(layers))): # from last to first\n",
    "        if i > 0:\n",
    "            grad_W = np.divide(np.dot(G, H[i - 1].T), Nb) + (2 * lmb * layer[\"W\"])\n",
    "            grad_b = np.divide(np.dot(G, np.ones((Nb, 1))), Nb)\n",
    "            G = np.dot(layer[\"W\"].T, G)\n",
    "            G = G * (H[i - 1] > 0).astype(int) # element-wise\n",
    "            \n",
    "            W_gradients.append(grad_W)\n",
    "            b_gradients.append(grad_b)\n",
    "        else: # first layer\n",
    "            grad_W = np.divide(np.dot(G, X.T), Nb) + (2 * lmb * layer[\"W\"])\n",
    "            grad_b = np.divide(np.dot(G, np.ones((Nb, 1))), Nb)\n",
    "            W_gradients.append(grad_W)\n",
    "            b_gradients.append(grad_b)\n",
    "    return W_gradients, b_gradients\n",
    "\n",
    "    \n",
    "def compute_gradients_num(X, Y, layers, lmb, h):\n",
    "    \n",
    "    grad_W = [np.zeros(layer[\"W\"].shape) for layer in layers]\n",
    "    grad_b = [np.zeros(layer[\"W\"].shape[0]) for layer in layers]\n",
    "    c = compute_cost(X, Y, layers, lmb)\n",
    "    \n",
    "    for l, layer in enumerate(layers):\n",
    "        for i in range(len(layer[\"b\"])):\n",
    "            layers_try = copy.deepcopy(layers)\n",
    "            layers_try[l][\"b\"][i] = layers_try[l][\"b\"][i] + h\n",
    "            c2 = compute_cost(X, Y, layers_try, lmb)\n",
    "            grad_b[l][i] = (c2 - c) / h\n",
    "\n",
    "        W_shape = layer[\"W\"].shape\n",
    "        for i in range(W_shape[0]):\n",
    "            for j in range(W_shape[1]):\n",
    "                layers_try = copy.deepcopy(layers)\n",
    "                layers_try[l][\"W\"][i,j] = layers_try[l][\"W\"][i,j] + h\n",
    "                c2 = compute_cost(X, Y, layers_try, lmb)\n",
    "                grad_W[l][i,j] = (c2 - c) / h\n",
    "        \n",
    "    return grad_W, grad_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(X, y, layers):\n",
    "    _, p = evaluate_classifier(X, layers)\n",
    "    argmax = np.argmax(p, axis=0) # max element index of each column\n",
    "    diff = argmax - y\n",
    "    return (diff == 0).sum() / X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mini_batch_GD(X, Y, GDparams, layers, lmb, validation, calculate_loss=False):\n",
    "#     print(\"Training samples: {}\".format(X.shape[1]))\n",
    "#     print(\"Validation samples: {}\".format(validation[\"X\"].shape[1]))\n",
    "#     print(\"Training parameters: \", GDparams)\n",
    "    J_training = []\n",
    "    J_validation = []\n",
    "    \n",
    "    eta_diff = GDparams[\"eta_max\"] - GDparams[\"eta_min\"]\n",
    "    eta = GDparams[\"eta_min\"]\n",
    "    t = 0 # step\n",
    "    l = 0 # cycle\n",
    "    \n",
    "    runs_in_epoch = int(X.shape[1] / GDparams[\"n_batch\"])\n",
    "    # for epoch in range(GDparams[\"epochs\"]):\n",
    "    while l < GDparams[\"max_cycles\"]:\n",
    "        for j in range(1, runs_in_epoch):\n",
    "            j_start = (j - 1) * GDparams[\"n_batch\"]\n",
    "            j_end = j * GDparams[\"n_batch\"]\n",
    "            \n",
    "            X_batch = X[:, j_start:j_end]\n",
    "            Y_batch = Y[:, j_start:j_end]\n",
    "            \n",
    "            grad_W, grad_b = compute_gradients(X_batch, Y_batch, layers, lmb)\n",
    "            \n",
    "            for i, layer in enumerate(layers):\n",
    "                layer[\"W\"] = layer[\"W\"] - (eta * grad_W[-1 - i])\n",
    "                layer[\"b\"] = layer[\"b\"] - (eta * grad_b[-1 - i])\n",
    "        \n",
    "            if calculate_loss and t % 100 == 0:\n",
    "                J_training.append(compute_cost(X, Y, layers, lmb))\n",
    "                J_validation.append(compute_cost(validation[\"X\"], validation[\"Y\"], layers, lmb))\n",
    "                print(\"Step {}, training loss: {}\".format(t, J_training[-1]))\n",
    "                \n",
    "            t += 1 # next update step\n",
    "            if t % (2 * GDparams[\"n_s\"]) == 0:\n",
    "                l += 1 # next cycle\n",
    "                if l == GDparams[\"max_cycles\"]:\n",
    "                    break\n",
    "#                 print(\"Entering cycle {}, t: {}, eta: {}\".format(l, t, eta))\n",
    "            if t <= (2*l + 1) * GDparams[\"n_s\"]:\n",
    "                eta = GDparams[\"eta_min\"] + (eta_diff * ((t - (2 * l * GDparams[\"n_s\"])) / GDparams[\"n_s\"]))\n",
    "            else:\n",
    "                eta = GDparams[\"eta_max\"] - (eta_diff * (t - ((2*l + 1) * GDparams[\"n_s\"])) / GDparams[\"n_s\"])\n",
    "\n",
    "    if calculate_loss:\n",
    "        return layers, J_training, J_validation\n",
    "    else:\n",
    "        return layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_batch': 100, 'eta_min': 1e-05, 'eta_max': 0.1, 'n_s': 500, 'epochs': 10, 'max_cycles': 1}\n"
     ]
    }
   ],
   "source": [
    "X, Y, y = load_batch('data/data_batch_1')\n",
    "X_valid, Y_valid, y_valid = load_batch('data/data_batch_2')\n",
    "# X, Y, y, X_valid, Y_valid, y_valid = load_all(validation_size=1000)\n",
    "X_test, Y_test, y_test = load_batch('data/test_batch')\n",
    "\n",
    "d = X.shape[0]\n",
    "N = X.shape[1]\n",
    "K = Y.shape[0]\n",
    "\n",
    "# X: d x N\n",
    "# Y: K x N\n",
    "\n",
    "m = 50 # hidden units\n",
    "\n",
    "std_dev_1 = 1 / np.sqrt(d)\n",
    "std_dev_2 = 1 / np.sqrt(m)\n",
    "# W_1 = std_dev * np.random.randn(m, d)\n",
    "# b_1 = std_dev * np.random.randn(m, 1)\n",
    "\n",
    "# W_2 = std_dev * np.random.randn(K, m)\n",
    "# b_2 = std_dev * np.random.randn(K, 1)\n",
    "def init_network(dimensions=d):\n",
    "    layers = [\n",
    "        {\n",
    "            \"W\": std_dev_1 * np.random.randn(m, dimensions),\n",
    "            \"b\": np.zeros((m, 1)),\n",
    "        },\n",
    "        {\n",
    "            \"W\": std_dev_2 * np.random.randn(K, m),\n",
    "            \"b\": np.zeros((K, 1)),\n",
    "        },\n",
    "    ]\n",
    "    return layers\n",
    "\n",
    "\n",
    "lmb = 0.01  # lambda\n",
    "GDparams = {\n",
    "    \"n_batch\": 100,\n",
    "    \"eta_min\": 1e-5,\n",
    "    \"eta_max\": 1e-1,\n",
    "    \"n_s\": 500,\n",
    "    \"epochs\": 10,\n",
    "    \"max_cycles\": 1,\n",
    "}\n",
    "#     \"n_s\": 2 * np.floor(X.shape[1] / 100),\n",
    "validation = {\n",
    "    \"X\": X_valid,\n",
    "    \"Y\": Y_valid,\n",
    "}\n",
    "\n",
    "print(GDparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0, training loss: 3.0498819193072886\n",
      "Step 100, training loss: 2.392219359086213\n",
      "Step 200, training loss: 2.168125606456703\n",
      "Step 300, training loss: 1.9972024663667383\n",
      "Step 400, training loss: 1.8961340311327568\n",
      "Step 500, training loss: 1.9102659598526244\n",
      "Step 600, training loss: 1.7218119718439329\n",
      "Step 700, training loss: 1.5877481266918752\n",
      "Step 800, training loss: 1.5396933653858766\n",
      "Step 900, training loss: 1.4785447861802798\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test cost:  1.8086210412224772\n",
      "Test accuracy:  0.4591\n"
     ]
    }
   ],
   "source": [
    "layers = init_network()\n",
    "layers_trained, J_training, J_validation = mini_batch_GD(X, Y, GDparams, layers, lmb, validation, calculate_loss=True)\n",
    "test_cost = compute_cost(X_test, Y_test, layers_trained, lmb)\n",
    "test_acc = compute_accuracy(X_test, y_test, layers_trained)\n",
    "\n",
    "plt.figure(0)\n",
    "plt.ylabel(\"Cost\")\n",
    "plt.xlabel(\"Step\")\n",
    "plt.plot([step*100 for step in range(len(J_training))], J_training, label=\"Training\")\n",
    "plt.plot([step*100 for step in range(len(J_validation))], J_validation, label=\"Validation\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(\"Test cost: \", test_cost)\n",
    "print(\"Test accuracy: \", test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "grad b:\n",
      "[[7.22620921e-07 2.04477735e-07 3.43940661e-07 0.00000000e+00\n",
      "  0.00000000e+00 3.72885493e-07 9.81260112e-07 0.00000000e+00\n",
      "  1.33911573e-07 0.00000000e+00 1.17774690e-06 0.00000000e+00\n",
      "  1.61974647e-07 0.00000000e+00 0.00000000e+00 2.08629169e-07\n",
      "  2.47794232e-07 0.00000000e+00 0.00000000e+00 2.63721484e-07\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 2.06335476e-06\n",
      "  7.58853713e-06 0.00000000e+00 1.84199899e-07 0.00000000e+00\n",
      "  3.88413830e-07 1.51827259e-07 4.25479314e-07 2.83864730e-07\n",
      "  1.86711403e-07 0.00000000e+00 0.00000000e+00 1.77481971e-07\n",
      "  4.80183069e-07 0.00000000e+00 0.00000000e+00 3.44832166e-07\n",
      "  3.02360513e-07 4.48643963e-07 1.77797009e-07 0.00000000e+00\n",
      "  0.00000000e+00 3.70674027e-07 3.82788220e-07 3.24558295e-07\n",
      "  1.20987290e-07 0.00000000e+00]]\n",
      "[[2.24521925e-06 2.26164420e-06 2.23953034e-06 2.24687523e-06\n",
      "  2.24781743e-06 2.25052211e-06 2.47856810e-07 2.25262913e-06\n",
      "  2.25260408e-06 2.25075809e-06]]\n",
      "\n",
      "grad W:\n",
      "[[7.15282834e-07 8.76597861e-07 8.19188144e-07 6.49239532e-07\n",
      "  3.56834705e-07 1.53946270e-07 4.51080816e-08 9.94154814e-08\n",
      "  1.33714631e-07 1.26858957e-07 5.87147627e-08 1.26057782e-07\n",
      "  4.97089662e-08 6.87137474e-08 5.30034869e-08 7.98631174e-08\n",
      "  6.12216044e-08 3.27380988e-08 1.37647027e-07 1.55053066e-08]\n",
      " [2.02486911e-07 2.48121589e-07 2.31890014e-07 1.83732064e-07\n",
      "  1.00892584e-07 4.40158449e-08 1.21761026e-08 2.76446116e-08\n",
      "  3.79695355e-08 3.61536530e-08 1.59043843e-08 3.51748944e-08\n",
      "  1.37850943e-08 2.04163773e-08 1.19066661e-08 2.33319623e-08\n",
      "  2.76488999e-08 1.00196378e-08 3.83194237e-08 3.09800075e-09]\n",
      " [3.40525355e-07 4.17271010e-07 3.89834514e-07 3.08970531e-07\n",
      "  1.69778267e-07 7.38587495e-08 1.96644751e-08 4.72838561e-08\n",
      "  6.38158315e-08 6.13295451e-08 2.83276938e-08 5.91383260e-08\n",
      "  2.19607614e-08 3.29265881e-08 1.04068156e-08 3.87228992e-08\n",
      "  4.96284982e-09 1.66834704e-08 6.46379375e-08 9.08567247e-09]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [3.69100472e-07 4.52314389e-07 4.22626908e-07 3.34880231e-07\n",
      "  1.83741058e-07 7.99382712e-08 2.21668524e-08 5.13504273e-08\n",
      "  6.84402217e-08 6.66949691e-08 2.97754263e-08 6.35774771e-08\n",
      "  2.33823920e-08 3.65403578e-08 2.88550337e-08 4.23086189e-08\n",
      "  1.99833149e-08 1.72372481e-08 6.99838177e-08 1.05712948e-08]\n",
      " [9.71288748e-07 1.19063410e-06 1.11225927e-06 8.80960553e-07\n",
      "  4.83581923e-07 2.10929692e-07 6.27899400e-08 1.38272650e-07\n",
      "  1.84252710e-07 1.75673952e-07 8.55366970e-08 1.69145814e-07\n",
      "  6.50176367e-08 9.72502054e-08 1.55118992e-07 1.13515529e-07\n",
      "  1.10873177e-07 4.14557060e-08 1.83589156e-07 3.79694870e-08]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [1.32580329e-07 1.62503467e-07 1.51827921e-07 1.20208481e-07\n",
      "  6.60771172e-08 2.83570253e-08 7.56016887e-09 1.78962780e-08\n",
      "  2.45811488e-08 2.40616394e-08 1.19612003e-08 2.28660720e-08\n",
      "  8.36599709e-09 1.36091022e-08 8.95999300e-09 1.53946029e-08\n",
      "  1.34190909e-08 6.73464861e-09 2.50867541e-08 5.80588074e-09]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [1.16637379e-06 1.42947037e-06 1.33564586e-06 1.05819366e-06\n",
      "  5.81412988e-07 2.51697670e-07 6.34752733e-08 1.62883615e-07\n",
      "  2.19073684e-07 2.09508632e-07 1.02223274e-07 2.02725949e-07\n",
      "  7.30926777e-08 1.16516357e-07 1.13081001e-07 1.34286516e-07\n",
      "  1.83749141e-07 5.25626931e-08 2.22134434e-07 2.45856069e-08]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [1.60609684e-07 1.96636572e-07 1.83716358e-07 1.45511033e-07\n",
      "  8.00279290e-08 3.46910797e-08 9.38035178e-09 2.21169036e-08\n",
      "  3.00160970e-08 2.84358071e-08 1.19907595e-08 2.71968823e-08\n",
      "  1.00657293e-08 1.46559660e-08 7.56250295e-09 1.73381840e-08\n",
      "  1.79464065e-08 7.50298010e-09 3.03488797e-08 2.99686105e-09]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [2.06558207e-07 2.53114473e-07 2.36543949e-07 1.87292275e-07\n",
      "  1.02954668e-07 4.46572705e-08 1.32869292e-08 2.81732510e-08\n",
      "  3.88880183e-08 3.74428399e-08 1.63243119e-08 3.59380570e-08\n",
      "  1.44700977e-08 2.13857231e-08 2.16642114e-08 2.31559470e-08\n",
      "  5.76726870e-08 1.15095495e-08 3.89629139e-08 8.00065480e-09]\n",
      " [2.45300419e-07 3.00631602e-07 2.80911156e-07 2.22564719e-07\n",
      "  1.22243324e-07 5.29369618e-08 1.43805061e-08 3.42330579e-08\n",
      "  4.59629662e-08 4.40147278e-08 1.98343903e-08 4.25216051e-08\n",
      "  1.62720620e-08 2.44190442e-08 6.81447482e-09 2.80684560e-08\n",
      "  2.58912695e-08 1.01562389e-08 4.63104777e-08 4.43772871e-09]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [2.61065051e-07 3.20023563e-07 2.98999233e-07 2.36906517e-07\n",
      "  1.30002183e-07 5.63175762e-08 1.55849494e-08 3.59257106e-08\n",
      "  4.86415030e-08 4.72023093e-08 2.19223875e-08 4.53947473e-08\n",
      "  1.68860272e-08 2.63027798e-08 4.20434062e-08 2.91246911e-08\n",
      "  8.95008014e-09 1.19807897e-08 4.91146204e-08 5.93278122e-09]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [2.04335933e-06 2.50386053e-06 2.33935283e-06 1.85326327e-06\n",
      "  1.01809572e-06 4.41873149e-07 1.31526281e-07 2.80015759e-07\n",
      "  3.78852268e-07 3.73195287e-07 1.60972152e-07 3.49052572e-07\n",
      "  1.24385400e-07 2.06872588e-07 4.74363389e-09 2.27546460e-07\n",
      "  9.48843221e-08 9.49352884e-08 3.92564467e-07 2.57955558e-08]\n",
      " [7.51740374e-06 9.20910579e-06 8.60586741e-06 6.81522155e-06\n",
      "  3.74462128e-06 1.63155180e-06 3.95588655e-07 1.02671992e-06\n",
      "  1.41104855e-06 1.33707453e-06 6.23702327e-07 1.30376666e-06\n",
      "  5.28859137e-07 7.39618670e-07 1.63023892e-06 8.47288520e-07\n",
      "  4.59723642e-07 4.16584807e-07 1.41256410e-06 1.95603066e-07]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [1.82509319e-07 2.23676825e-07 2.08938173e-07 1.65584947e-07\n",
      "  9.10090078e-08 3.90398900e-08 9.05670662e-09 2.54008017e-08\n",
      "  3.43679570e-08 3.32648555e-08 1.50949930e-08 3.15860165e-08\n",
      "  1.22656227e-08 1.81256536e-08 5.24762220e-08 2.14464608e-08\n",
      "  6.09899574e-08 5.00092158e-09 3.50635099e-08 6.22467595e-09]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [3.84680153e-07 4.71148358e-07 4.40411184e-07 3.48991654e-07\n",
      "  1.91386596e-07 8.33646490e-08 2.18828304e-08 5.31093331e-08\n",
      "  7.25115000e-08 6.92005961e-08 3.31963405e-08 6.62430557e-08\n",
      "  2.27576308e-08 3.81948755e-08 7.69189585e-08 4.42094705e-08\n",
      "  7.25275284e-09 1.41226236e-08 7.33099184e-08 1.25843247e-08]\n",
      " [1.50354848e-07 1.84254077e-07 1.72210780e-07 1.36409298e-07\n",
      "  7.49961067e-08 3.25279758e-08 7.66784545e-09 2.04598466e-08\n",
      "  2.80653466e-08 2.71307299e-08 1.21822788e-08 2.55275259e-08\n",
      "  9.05800467e-09 1.43940617e-08 2.83949285e-08 1.66116063e-08\n",
      "  1.36930331e-08 6.23360066e-09 2.85981137e-08 3.17961179e-09]\n",
      " [4.21339536e-07 5.16326341e-07 4.82349956e-07 3.82248307e-07\n",
      "  2.10088754e-07 9.13393724e-08 2.60564596e-08 5.78527284e-08\n",
      "  7.83017537e-08 7.55915302e-08 3.59409098e-08 7.25048731e-08\n",
      "  2.84904568e-08 4.12289136e-08 2.13314769e-08 4.80103415e-08\n",
      "  2.69105155e-08 1.70699573e-08 8.00453023e-08 1.19763977e-08]\n",
      " [2.81075642e-07 3.44448967e-07 3.21819414e-07 2.55012548e-07\n",
      "  1.40054793e-07 6.05474065e-08 1.67602577e-08 3.88296926e-08\n",
      "  5.28247901e-08 5.07565562e-08 2.23093641e-08 4.81229220e-08\n",
      "  1.80536071e-08 2.71261418e-08 1.93247203e-08 3.24245116e-08\n",
      "  1.41167299e-09 1.38909998e-08 5.32980666e-08 6.42354699e-09]\n",
      " [1.84825490e-07 2.26535301e-07 2.11681790e-07 1.67664485e-07\n",
      "  9.19270457e-08 4.05068255e-08 1.09692613e-08 2.61586103e-08\n",
      "  3.43737409e-08 3.30268015e-08 1.54016512e-08 3.19944405e-08\n",
      "  1.26474010e-08 1.79853881e-08 3.27650705e-08 2.04414840e-08\n",
      "  2.19997302e-08 7.73113370e-09 3.51248319e-08 5.33945532e-09]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [1.75716824e-07 2.15355543e-07 2.01243860e-07 1.59467839e-07\n",
      "  8.75037123e-08 3.79909812e-08 1.03891504e-08 2.44158885e-08\n",
      "  3.28976965e-08 3.14391120e-08 1.41701215e-08 3.01879008e-08\n",
      "  1.13098638e-08 1.71359832e-08 3.46065109e-10 1.98384197e-08\n",
      "  2.77735413e-09 7.77324841e-09 3.34088770e-08 4.80937552e-09]\n",
      " [4.75457801e-07 5.82779931e-07 5.44453232e-07 4.31231048e-07\n",
      "  2.37203690e-07 1.02284058e-07 2.65336372e-08 6.60435273e-08\n",
      "  8.83622371e-08 8.51307185e-08 3.93181340e-08 8.10218848e-08\n",
      "  3.18978991e-08 4.65841732e-08 3.50565020e-09 5.33206035e-08\n",
      "  2.72890009e-08 2.32730367e-08 8.98966792e-08 8.90258050e-09]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [3.41441583e-07 4.18337178e-07 3.90849852e-07 3.09603443e-07\n",
      "  1.70193118e-07 7.39024776e-08 2.16583203e-08 4.62064359e-08\n",
      "  6.43022213e-08 6.14677494e-08 2.69228410e-08 5.85622447e-08\n",
      "  2.08941165e-08 3.44201752e-08 2.02435303e-08 3.76597213e-08\n",
      "  4.55101349e-08 1.67664713e-08 6.54961619e-08 6.78824373e-09]\n",
      " [2.99389156e-07 3.66870259e-07 3.42813162e-07 2.71623445e-07\n",
      "  1.49245135e-07 6.45801377e-08 1.64228076e-08 4.19196402e-08\n",
      "  5.59317913e-08 5.42935615e-08 2.45501716e-08 5.15794427e-08\n",
      "  1.85185809e-08 2.89287561e-08 4.48910270e-08 3.37510057e-08\n",
      "  2.32465526e-08 1.31739969e-08 5.67709123e-08 8.57587933e-09]\n",
      " [4.44231919e-07 5.44367008e-07 5.08695148e-07 4.02953652e-07\n",
      "  2.21362341e-07 9.59197294e-08 2.59760645e-08 6.17264070e-08\n",
      "  8.31379795e-08 7.95202209e-08 3.65964943e-08 7.65156389e-08\n",
      "  2.82815177e-08 4.24420700e-08 1.25748816e-08 5.02678525e-08\n",
      "  8.54423284e-09 2.19655190e-08 8.46213690e-08 1.21761327e-08]\n",
      " [1.75834133e-07 2.15598855e-07 2.01567346e-07 1.59858927e-07\n",
      "  8.76195544e-08 3.75516228e-08 1.02861078e-08 2.48520383e-08\n",
      "  3.20142645e-08 3.10449531e-08 1.58460159e-08 3.06586646e-08\n",
      "  1.11327744e-08 1.66550719e-08 4.17734312e-08 2.02876346e-08\n",
      "  6.85561120e-08 9.79347822e-09 3.34827738e-08 8.71275784e-10]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [3.67239827e-07 4.49940136e-07 4.20362669e-07 3.32982140e-07\n",
      "  1.82894153e-07 7.90174285e-08 2.12996240e-08 5.06097776e-08\n",
      "  6.86924050e-08 6.56782567e-08 2.85766693e-08 6.30992070e-08\n",
      "  2.53990999e-08 3.70270633e-08 6.35109600e-08 4.17574826e-08\n",
      "  5.21299640e-08 1.86160405e-08 6.99684673e-08 8.19841432e-09]\n",
      " [3.79093214e-07 4.64489936e-07 4.34027857e-07 3.43752011e-07\n",
      "  1.88895652e-07 8.17556171e-08 2.25562722e-08 5.29584868e-08\n",
      "  7.13450696e-08 6.86162055e-08 3.21413906e-08 6.55240864e-08\n",
      "  2.35579542e-08 3.67216242e-08 2.89245315e-08 4.30410148e-08\n",
      "  2.61092693e-08 1.69108646e-08 7.12243640e-08 5.55270981e-09]\n",
      " [3.21479942e-07 3.93863612e-07 3.68007165e-07 2.91575141e-07\n",
      "  1.60195420e-07 6.95995280e-08 1.81043145e-08 4.47946513e-08\n",
      "  6.02557918e-08 5.79576001e-08 2.69992617e-08 5.52276822e-08\n",
      "  2.24600714e-08 3.12445779e-08 1.16006699e-08 3.60853315e-08\n",
      "  2.06595470e-08 1.67641204e-08 6.09213547e-08 6.78257925e-09]\n",
      " [1.19953132e-07 1.47028533e-07 1.37205606e-07 1.08456297e-07\n",
      "  5.95474640e-08 2.61928013e-08 7.52269278e-09 1.60260458e-08\n",
      "  2.20040495e-08 2.12202686e-08 8.22576394e-09 2.01453879e-08\n",
      "  9.53286726e-09 1.18137629e-08 1.02678260e-07 1.21328216e-08\n",
      "  1.70153482e-08 6.40988914e-09 2.30263067e-08 6.51612236e-09]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]]\n",
      "[[1.37736758e-07 1.64827286e-07 2.95028628e-08 0.00000000e+00\n",
      "  0.00000000e+00 4.77516470e-08 7.84714087e-08 0.00000000e+00\n",
      "  3.61211932e-08 0.00000000e+00 5.15337800e-08 0.00000000e+00\n",
      "  8.62928579e-08 0.00000000e+00 0.00000000e+00 2.77599068e-08\n",
      "  4.30102837e-09 0.00000000e+00 0.00000000e+00 8.20284573e-08\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 6.74265702e-08\n",
      "  9.73600395e-08 0.00000000e+00 2.52893254e-08 0.00000000e+00\n",
      "  7.74308645e-09 1.13040157e-07 4.11445439e-08 5.88246534e-08\n",
      "  1.40246226e-07 0.00000000e+00 0.00000000e+00 1.42892197e-07\n",
      "  9.22447281e-08 0.00000000e+00 0.00000000e+00 3.01852553e-07\n",
      "  1.61126087e-07 9.04790323e-08 1.68310519e-08 0.00000000e+00\n",
      "  0.00000000e+00 9.36698774e-08 1.28230364e-07 2.12953550e-09\n",
      "  1.08559971e-07 0.00000000e+00]\n",
      " [1.38002527e-07 1.64854635e-07 1.62358916e-08 0.00000000e+00\n",
      "  0.00000000e+00 5.20605534e-08 7.65011888e-08 0.00000000e+00\n",
      "  2.75052781e-08 0.00000000e+00 5.43679432e-08 0.00000000e+00\n",
      "  8.53013273e-08 0.00000000e+00 0.00000000e+00 1.81014178e-08\n",
      "  4.88988729e-08 0.00000000e+00 0.00000000e+00 1.55727439e-07\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 6.78504197e-08\n",
      "  9.65894183e-08 0.00000000e+00 2.33863466e-08 0.00000000e+00\n",
      "  2.04364707e-08 1.17091276e-07 3.37530056e-08 5.86220226e-08\n",
      "  1.44471340e-07 0.00000000e+00 0.00000000e+00 1.45314775e-07\n",
      "  9.43589728e-08 0.00000000e+00 0.00000000e+00 3.03450661e-07\n",
      "  1.62604164e-07 9.14586174e-08 1.96030259e-08 0.00000000e+00\n",
      "  0.00000000e+00 9.39229070e-08 1.27498219e-07 6.00965666e-09\n",
      "  1.11703688e-07 0.00000000e+00]\n",
      " [1.38002984e-07 1.64391992e-07 1.41490095e-08 0.00000000e+00\n",
      "  0.00000000e+00 5.32693724e-08 7.81158566e-08 0.00000000e+00\n",
      "  3.44450759e-08 0.00000000e+00 4.97017745e-08 0.00000000e+00\n",
      "  8.41487694e-08 0.00000000e+00 0.00000000e+00 2.16847582e-08\n",
      "  4.40058308e-08 0.00000000e+00 0.00000000e+00 5.19629421e-08\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 6.93147568e-08\n",
      "  9.39598920e-08 0.00000000e+00 2.56839915e-08 0.00000000e+00\n",
      "  2.79065373e-08 1.11728703e-07 4.60665539e-08 5.99858356e-08\n",
      "  1.42508443e-07 0.00000000e+00 0.00000000e+00 1.43800885e-07\n",
      "  9.11810996e-08 0.00000000e+00 0.00000000e+00 3.00624144e-07\n",
      "  1.63180910e-07 8.65604378e-08 1.97706770e-08 0.00000000e+00\n",
      "  0.00000000e+00 9.00345498e-08 1.26363540e-07 3.98980939e-09\n",
      "  1.10064576e-07 0.00000000e+00]\n",
      " [1.35792661e-07 1.62873220e-07 8.39468288e-09 0.00000000e+00\n",
      "  0.00000000e+00 4.93200631e-08 7.33605499e-08 0.00000000e+00\n",
      "  3.89788422e-08 0.00000000e+00 4.87437677e-08 0.00000000e+00\n",
      "  8.58300616e-08 0.00000000e+00 0.00000000e+00 2.78948462e-08\n",
      "  6.05997092e-10 0.00000000e+00 0.00000000e+00 1.87382508e-08\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 7.22054871e-08\n",
      "  9.60666463e-08 0.00000000e+00 2.68878699e-08 0.00000000e+00\n",
      "  1.66046154e-08 1.13001633e-07 4.26089601e-08 5.42540892e-08\n",
      "  1.40384830e-07 0.00000000e+00 0.00000000e+00 1.42665035e-07\n",
      "  9.09685692e-08 0.00000000e+00 0.00000000e+00 3.00190965e-07\n",
      "  1.63469151e-07 8.82876330e-08 2.83511498e-09 0.00000000e+00\n",
      "  0.00000000e+00 9.35879847e-08 1.27085695e-07 4.95333448e-09\n",
      "  1.11058037e-07 0.00000000e+00]\n",
      " [1.36412689e-07 1.63053309e-07 1.59294137e-08 0.00000000e+00\n",
      "  0.00000000e+00 5.10120625e-08 7.75453947e-08 0.00000000e+00\n",
      "  4.17742998e-08 0.00000000e+00 4.95918452e-08 0.00000000e+00\n",
      "  8.19214204e-08 0.00000000e+00 0.00000000e+00 3.00899387e-08\n",
      "  3.19552916e-09 0.00000000e+00 0.00000000e+00 7.57867564e-08\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 6.87057234e-08\n",
      "  9.58423714e-08 0.00000000e+00 2.87390310e-08 0.00000000e+00\n",
      "  2.01463261e-08 1.13653394e-07 3.59787031e-08 5.54878481e-08\n",
      "  1.39355863e-07 0.00000000e+00 0.00000000e+00 1.45320356e-07\n",
      "  9.40772850e-08 0.00000000e+00 0.00000000e+00 3.00928011e-07\n",
      "  1.61707434e-07 8.80689413e-08 1.02380861e-08 0.00000000e+00\n",
      "  0.00000000e+00 9.62355435e-08 1.29030710e-07 5.94200560e-09\n",
      "  1.09112784e-07 0.00000000e+00]\n",
      " [1.38804218e-07 1.63215241e-07 7.95842453e-09 0.00000000e+00\n",
      "  0.00000000e+00 5.32918908e-08 7.54215767e-08 0.00000000e+00\n",
      "  2.54536796e-08 0.00000000e+00 5.15138216e-08 0.00000000e+00\n",
      "  8.63227052e-08 0.00000000e+00 0.00000000e+00 3.06057351e-08\n",
      "  2.13852704e-08 0.00000000e+00 0.00000000e+00 6.00075723e-09\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 7.08022339e-08\n",
      "  9.36321810e-08 0.00000000e+00 2.32088480e-08 0.00000000e+00\n",
      "  1.55824782e-08 1.13202451e-07 4.33274437e-08 6.01159853e-08\n",
      "  1.41490350e-07 0.00000000e+00 0.00000000e+00 1.44005719e-07\n",
      "  9.49569565e-08 0.00000000e+00 0.00000000e+00 3.00644585e-07\n",
      "  1.60632425e-07 8.99187683e-08 6.90110374e-09 0.00000000e+00\n",
      "  0.00000000e+00 9.38913692e-08 1.30096667e-07 2.97386406e-09\n",
      "  1.09204747e-07 0.00000000e+00]\n",
      " [1.52001757e-08 1.80723053e-08 1.53992385e-09 0.00000000e+00\n",
      "  0.00000000e+00 5.52487789e-09 7.84482404e-09 0.00000000e+00\n",
      "  2.28227825e-09 0.00000000e+00 5.66652716e-09 0.00000000e+00\n",
      "  9.66384786e-09 0.00000000e+00 0.00000000e+00 2.19529449e-09\n",
      "  4.93677832e-09 0.00000000e+00 0.00000000e+00 9.82012496e-09\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 7.34935856e-09\n",
      "  1.03148861e-08 0.00000000e+00 2.91672617e-09 0.00000000e+00\n",
      "  1.17134815e-09 1.23629709e-08 4.34825758e-09 6.05426087e-09\n",
      "  1.57836374e-08 0.00000000e+00 0.00000000e+00 1.60097675e-08\n",
      "  1.02876023e-08 0.00000000e+00 0.00000000e+00 3.31598860e-08\n",
      "  1.79036081e-08 9.39366662e-09 8.08474039e-11 0.00000000e+00\n",
      "  0.00000000e+00 1.02615766e-08 1.41050871e-08 1.78282658e-09\n",
      "  1.19625661e-08 0.00000000e+00]\n",
      " [1.36030021e-07 1.63177533e-07 1.51453588e-08 0.00000000e+00\n",
      "  0.00000000e+00 5.20285410e-08 7.61549882e-08 0.00000000e+00\n",
      "  3.64805588e-08 0.00000000e+00 4.86034955e-08 0.00000000e+00\n",
      "  8.38480462e-08 0.00000000e+00 0.00000000e+00 3.48726181e-08\n",
      "  4.78802677e-08 0.00000000e+00 0.00000000e+00 5.74558670e-08\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 6.71732484e-08\n",
      "  9.51973493e-08 0.00000000e+00 2.71048722e-08 0.00000000e+00\n",
      "  2.08553722e-08 1.13572517e-07 3.67606596e-08 5.51123753e-08\n",
      "  1.44032675e-07 0.00000000e+00 0.00000000e+00 1.43583082e-07\n",
      "  9.38301068e-08 0.00000000e+00 0.00000000e+00 3.01047579e-07\n",
      "  1.61096274e-07 9.17869203e-08 2.82723748e-08 0.00000000e+00\n",
      "  0.00000000e+00 9.27150724e-08 1.27870701e-07 4.11233312e-09\n",
      "  1.11428565e-07 0.00000000e+00]\n",
      " [1.39052667e-07 1.63983412e-07 1.24355012e-08 0.00000000e+00\n",
      "  0.00000000e+00 5.23401330e-08 7.67515526e-08 0.00000000e+00\n",
      "  3.44889907e-08 0.00000000e+00 5.43632504e-08 0.00000000e+00\n",
      "  8.90209655e-08 0.00000000e+00 0.00000000e+00 3.64749412e-08\n",
      "  1.55117284e-08 0.00000000e+00 0.00000000e+00 6.93786972e-08\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 6.62331521e-08\n",
      "  9.73680686e-08 0.00000000e+00 3.08520687e-08 0.00000000e+00\n",
      "  2.51316856e-08 1.11886664e-07 4.12574909e-08 5.26903548e-08\n",
      "  1.43353170e-07 0.00000000e+00 0.00000000e+00 1.46462741e-07\n",
      "  9.26688030e-08 0.00000000e+00 0.00000000e+00 3.01745541e-07\n",
      "  1.63979955e-07 8.78951544e-08 4.66130626e-09 0.00000000e+00\n",
      "  0.00000000e+00 9.63917558e-08 1.26757716e-07 1.87494078e-08\n",
      "  1.10549419e-07 0.00000000e+00]\n",
      " [1.36979789e-07 1.63833741e-07 2.23552952e-08 0.00000000e+00\n",
      "  0.00000000e+00 4.72951328e-08 7.16382794e-08 0.00000000e+00\n",
      "  3.63758196e-08 0.00000000e+00 5.76325868e-08 0.00000000e+00\n",
      "  8.36461583e-08 0.00000000e+00 0.00000000e+00 2.09791326e-08\n",
      "  3.25700375e-08 0.00000000e+00 0.00000000e+00 6.40063008e-08\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 6.89351082e-08\n",
      "  9.33412168e-08 0.00000000e+00 3.05663372e-08 0.00000000e+00\n",
      "  1.88848451e-08 1.13595787e-07 3.81468562e-08 5.36442637e-08\n",
      "  1.40916986e-07 0.00000000e+00 0.00000000e+00 1.45874224e-07\n",
      "  9.72360075e-08 0.00000000e+00 0.00000000e+00 3.01499114e-07\n",
      "  1.62138408e-07 9.16360857e-08 1.64854898e-08 0.00000000e+00\n",
      "  0.00000000e+00 9.06269928e-08 1.27699319e-07 6.63816375e-09\n",
      "  1.08048852e-07 0.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "feature_dims = 20\n",
    "samples = 1\n",
    "\n",
    "layers_g = init_network(dimensions=feature_dims)\n",
    "X_g = X[0:feature_dims, 0:samples] #d X N\n",
    "Y_g = Y[:, 0:samples] #K x N\n",
    "\n",
    "grad_W, grad_b = compute_gradients(X_g, Y_g, layers_g, lmb=0)\n",
    "ngrad_w, ngrad_b = compute_gradients_num(X_g, Y_g, layers_g, lmb=0, h=1e-5)\n",
    "print(\"\\ngrad b:\")\n",
    "\n",
    "print(np.abs(grad_b[1].T - ngrad_b[0]) / np.maximum(1e-5, np.abs(grad_b[1].T) + np.abs(ngrad_b[0])))\n",
    "print(np.abs(grad_b[0].T - ngrad_b[1]) / np.maximum(1e-5, np.abs(grad_b[0].T) + np.abs(ngrad_b[1])))\n",
    "\n",
    "print(\"\\ngrad W:\")\n",
    "print(np.abs(grad_W[1] - ngrad_w[0]) / np.maximum(1e-5, np.abs(grad_W[1]) + np.abs(ngrad_w[0])))\n",
    "print(np.abs(grad_W[0] - ngrad_w[1]) / np.maximum(1e-5, np.abs(grad_W[0]) + np.abs(ngrad_w[1])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lambda: 1.6284587893989866e-07 (l: -6.788223227435661), test cost: 1.3955476758729672, test accuracy: 0.5132\n",
      "Lambda: 1.9433438313018646e-07 (l: -6.711450353889899), test cost: 1.3919308043169243, test accuracy: 0.517\n",
      "Lambda: 3.056436545874993e-07 (l: -6.514784616089612), test cost: 1.3939520376447685, test accuracy: 0.5142\n",
      "Lambda: 3.5712004431965055e-07 (l: -6.447185773181305), test cost: 1.4108065471022475, test accuracy: 0.5093\n",
      "Lambda: 7.390586553404944e-07 (l: -6.131321092484978), test cost: 1.4068398276676728, test accuracy: 0.5086\n",
      "Lambda: 8.521334979178329e-07 (l: -6.069492361961749), test cost: 1.4000591986331568, test accuracy: 0.5107\n",
      "Lambda: 8.997257824166672e-07 (l: -6.045889834260329), test cost: 1.404094918824293, test accuracy: 0.509\n",
      "Lambda: 1.681239486847397e-06 (l: -5.774370418381956), test cost: 1.404773911688305, test accuracy: 0.5098\n",
      "Lambda: 2.3633480660796677e-06 (l: -5.626472312203524), test cost: 1.4111979526545093, test accuracy: 0.5052\n",
      "Lambda: 5.772363874301318e-06 (l: -5.238646299958964), test cost: 1.4014209286568786, test accuracy: 0.5118\n",
      "Lambda: 7.1591754517536755e-06 (l: -5.145136994085203), test cost: 1.403699969911985, test accuracy: 0.5093\n",
      "Lambda: 7.6211906487915946e-06 (l: -5.117977174092729), test cost: 1.4018612985279004, test accuracy: 0.5091\n",
      "Lambda: 9.945254604581737e-06 (l: -5.00238409419369), test cost: 1.395102013676661, test accuracy: 0.5076\n",
      "Lambda: 1.4297519591968112e-05 (l: -4.844739299664814), test cost: 1.404671706881865, test accuracy: 0.509\n",
      "Lambda: 2.1575426685460984e-05 (l: -4.666040606722424), test cost: 1.4100266383744948, test accuracy: 0.5092\n",
      "Lambda: 2.3109726324061813e-05 (l: -4.636205197604125), test cost: 1.3936841661499442, test accuracy: 0.5092\n",
      "Lambda: 3.708480776242123e-05 (l: -4.43080396791108), test cost: 1.4096875262790625, test accuracy: 0.5075\n",
      "Lambda: 5.0862391397591246e-05 (l: -4.293603224452046), test cost: 1.4114764369616486, test accuracy: 0.5129\n",
      "Lambda: 8.32981781239754e-05 (l: -4.079364497264964), test cost: 1.410129965823496, test accuracy: 0.5108\n",
      "Lambda: 0.00022898100715200843 (l: -3.6402005387568575), test cost: 1.4223053865713202, test accuracy: 0.5096\n",
      "Lambda: 0.0006209245540174268 (l: -3.206961165949748), test cost: 1.448288750259849, test accuracy: 0.5091\n",
      "Lambda: 0.000814024070237211 (l: -3.0893627530756094), test cost: 1.4493419714745006, test accuracy: 0.5151\n",
      "Lambda: 0.0008880790020642598 (l: -3.0515483983718115), test cost: 1.4550647756586983, test accuracy: 0.5109\n",
      "Lambda: 0.0009096517413231822 (l: -3.04112484478904), test cost: 1.4634165111431936, test accuracy: 0.5111\n",
      "Lambda: 0.0018026397945586723 (l: -2.744091045803393), test cost: 1.4868485092796246, test accuracy: 0.5112\n",
      "Lambda: 0.006088551747151061 (l: -2.2154859985033317), test cost: 1.533140238496957, test accuracy: 0.5135\n",
      "Lambda: 0.009524497059850005 (l: -2.0211579479251727), test cost: 1.5695906275192764, test accuracy: 0.5053\n",
      "Lambda: 0.010629835702420366 (l: -1.9734734479963318), test cost: 1.5806770625833453, test accuracy: 0.5066\n",
      "Lambda: 0.013908989239557348 (l: -1.8567044288600156), test cost: 1.6130300413829894, test accuracy: 0.4996\n",
      "Lambda: 0.021016207180621912 (l: -1.6774456588669544), test cost: 1.6705108275810636, test accuracy: 0.4918\n",
      "Lambda: 0.02326905434426635 (l: -1.6332212661078591), test cost: 1.6849888747857742, test accuracy: 0.4838\n",
      "Lambda: 0.025328624492786077 (l: -1.5963883945526494), test cost: 1.7014963845155169, test accuracy: 0.4799\n",
      "Lambda: 0.030470631323613016 (l: -1.5161185474996426), test cost: 1.731310469433345, test accuracy: 0.4746\n",
      "Lambda: 0.03981861199285087 (l: -1.3999138827905764), test cost: 1.7847885804879904, test accuracy: 0.4588\n",
      "Lambda: 0.05746146716452868 (l: -1.2406232893547884), test cost: 1.8563885000633948, test accuracy: 0.4323\n",
      "Lambda: 0.06519426196301524 (l: -1.1857906267751677), test cost: 1.8844473837253035, test accuracy: 0.4188\n",
      "Lambda: 0.06884795384394662 (l: -1.1621089624148722), test cost: 1.8931384477967463, test accuracy: 0.4178\n",
      "Lambda: 0.09746296581002624 (l: -1.0111603771191913), test cost: 1.9636360291761636, test accuracy: 0.3919\n",
      "Lambda: 0.15569906521594262 (l: -0.8077139948357113), test cost: 2.0519596829032714, test accuracy: 0.3521\n",
      "Lambda: 0.17944171915831694 (l: -0.7460765786059067), test cost: 2.077231264451248, test accuracy: 0.3408\n"
     ]
    }
   ],
   "source": [
    "# Searching for lambda (coarse)\n",
    "l_min = -7\n",
    "l_max = -0.5\n",
    "\n",
    "ls = np.sort([np.random.uniform(l_min, l_max) for i in range(40)])\n",
    "for l in ls:\n",
    "    lmb = np.power(10, l)\n",
    "    layers = init_network()\n",
    "    layers_trained = mini_batch_GD(X, Y, GDparams, layers, lmb, validation)\n",
    "    test_cost = compute_cost(X_test, Y_test, layers_trained, lmb)\n",
    "    test_acc = compute_accuracy(X_test, y_test, layers_trained)\n",
    "    print(\"Lambda: {} (l: {}), test cost: {}, test accuracy: {}\".format(lmb, l, test_cost, test_acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lambda: 0.00071248749330148 (l: -3.1472227546707865), test cost: 1.4510756984427802, test accuracy: 0.5099\n",
      "Lambda: 0.0007146232764639532 (l: -3.1459228422124754), test cost: 1.445761949523194, test accuracy: 0.5136\n",
      "Lambda: 0.0007259585887334052 (l: -3.13908815229924), test cost: 1.4462508747087506, test accuracy: 0.5177\n",
      "Lambda: 0.0007782678867742624 (l: -3.108870889228044), test cost: 1.4491521275418415, test accuracy: 0.5154\n",
      "Lambda: 0.0008077652925526167 (l: -3.0927148112015628), test cost: 1.4508162866347136, test accuracy: 0.5143\n",
      "Lambda: 0.0008796213601880293 (l: -3.0557042330411712), test cost: 1.4647637385936567, test accuracy: 0.5118\n",
      "Lambda: 0.0009808860205645364 (l: -3.008381454919501), test cost: 1.4525600055983214, test accuracy: 0.5156\n",
      "Lambda: 0.0010307469960792377 (l: -2.9868479221954005), test cost: 1.4731967662924745, test accuracy: 0.5118\n",
      "Lambda: 0.0010696752797705368 (l: -2.9707480406390325), test cost: 1.4638358700561023, test accuracy: 0.5148\n",
      "Lambda: 0.001080292878201633 (l: -2.9664584869729484), test cost: 1.4694205426565476, test accuracy: 0.5083\n",
      "Lambda: 0.0011037126895251054 (l: -2.957143964281637), test cost: 1.469866140921399, test accuracy: 0.5112\n",
      "Lambda: 0.0011866482865510555 (l: -2.92567798352595), test cost: 1.469662457322351, test accuracy: 0.5084\n",
      "Lambda: 0.0012589643160096288 (l: -2.8999865793279884), test cost: 1.464356460784085, test accuracy: 0.5134\n",
      "Lambda: 0.0012831058967807164 (l: -2.8917374991280846), test cost: 1.4684733861665245, test accuracy: 0.5166\n",
      "Lambda: 0.0015005191445994577 (l: -2.823758459192236), test cost: 1.4767125800723164, test accuracy: 0.5139\n",
      "Lambda: 0.0015063518701670432 (l: -2.822073569023518), test cost: 1.4815432480785264, test accuracy: 0.5081\n",
      "Lambda: 0.0016952572301166108 (l: -2.7707643947208678), test cost: 1.474770934654416, test accuracy: 0.5163\n",
      "Lambda: 0.0017434248369922103 (l: -2.758596771306743), test cost: 1.4826602926348762, test accuracy: 0.5082\n",
      "Lambda: 0.001781539489961128 (l: -2.7492045465478077), test cost: 1.4903829604839414, test accuracy: 0.5092\n",
      "Lambda: 0.0017819383830928123 (l: -2.749107317328009), test cost: 1.4855955112295642, test accuracy: 0.5146\n",
      "Lambda: 0.0017992587427827194 (l: -2.744906378353924), test cost: 1.491203161895623, test accuracy: 0.5101\n",
      "Lambda: 0.0019526794038930066 (l: -2.7093690544844926), test cost: 1.4899646712556682, test accuracy: 0.5118\n",
      "Lambda: 0.0021041300397713694 (l: -2.6769274233538773), test cost: 1.4888816359466788, test accuracy: 0.5141\n",
      "Lambda: 0.002179627728320391 (l: -2.6616176758184245), test cost: 1.4925143571507768, test accuracy: 0.5121\n",
      "Lambda: 0.002251858982616876 (l: -2.647458809641697), test cost: 1.486431513446303, test accuracy: 0.5135\n",
      "Lambda: 0.0028834599935239386 (l: -2.5400860698165744), test cost: 1.5052832914411325, test accuracy: 0.5125\n",
      "Lambda: 0.003255868782093263 (l: -2.487333106350759), test cost: 1.5005878266908785, test accuracy: 0.5144\n",
      "Lambda: 0.0037883842668760557 (l: -2.4215459756772786), test cost: 1.5157198318003935, test accuracy: 0.5118\n",
      "Lambda: 0.0037935293081345343 (l: -2.420956556304821), test cost: 1.50779699461601, test accuracy: 0.5158\n",
      "Lambda: 0.003949615464177995 (l: -2.403445185364679), test cost: 1.5049526235530344, test accuracy: 0.5146\n",
      "Lambda: 0.004579147821974501 (l: -2.339215336548387), test cost: 1.5216918635153915, test accuracy: 0.5121\n",
      "Lambda: 0.004584855540260638 (l: -2.3386743435394406), test cost: 1.5169469983093282, test accuracy: 0.5155\n",
      "Lambda: 0.0047289191098337695 (l: -2.325238114712273), test cost: 1.5180556285495759, test accuracy: 0.517\n",
      "Lambda: 0.0047658945416409445 (l: -2.3218555718280287), test cost: 1.5225689862759595, test accuracy: 0.512\n",
      "Lambda: 0.0047761928557153365 (l: -2.3209181453456105), test cost: 1.5232101603312542, test accuracy: 0.5096\n",
      "Lambda: 0.005427356747752031 (l: -2.265411630698389), test cost: 1.5311726562711363, test accuracy: 0.5102\n",
      "Lambda: 0.005467076375028544 (l: -2.262244858974409), test cost: 1.5270082748798472, test accuracy: 0.5152\n",
      "Lambda: 0.005826070123680577 (l: -2.234624292426469), test cost: 1.5278177177935222, test accuracy: 0.5137\n",
      "Lambda: 0.006054149158778783 (l: -2.217946883340372), test cost: 1.5346410135726747, test accuracy: 0.5112\n",
      "Lambda: 0.006233399272999933 (l: -2.2052750539989057), test cost: 1.5389822681281164, test accuracy: 0.5109\n"
     ]
    }
   ],
   "source": [
    "# Searching for lambda (fine)\n",
    "l_min = -3.2\n",
    "l_max = -2.2\n",
    "\n",
    "ls = np.sort([np.random.uniform(l_min, l_max) for i in range(40)])\n",
    "for l in ls:\n",
    "    lmb = np.power(10, l)\n",
    "    layers = init_network()\n",
    "    layers_trained = mini_batch_GD(X, Y, GDparams, layers, lmb, validation)\n",
    "    test_cost = compute_cost(X_test, Y_test, layers_trained, lmb)\n",
    "    test_acc = compute_accuracy(X_test, y_test, layers_trained)\n",
    "    print(\"Lambda: {} (l: {}), test cost: {}, test accuracy: {}\".format(lmb, l, test_cost, test_acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test cost: 1.4662692267907325\n",
      "Test accuracy: 0.5033\n",
      "\n",
      "Test cost: 1.4734380766557735\n",
      "Test accuracy: 0.5091\n",
      "\n",
      "Test cost: 1.5240595621558624\n",
      "Test accuracy: 0.5113\n"
     ]
    }
   ],
   "source": [
    "best_ls = [-3.13908815229924, -2.8917374991280846, -2.325238114712273]\n",
    "for l in best_ls:\n",
    "    lmb = np.power(10, l)\n",
    "    layers = init_network()\n",
    "    layers_trained = mini_batch_GD(X, Y, GDparams, layers, lmb, validation)\n",
    "    test_cost = compute_cost(X_test, Y_test, layers_trained, lmb)\n",
    "    test_acc = compute_accuracy(X_test, y_test, layers_trained)\n",
    "\n",
    "    print(\"\\nTest cost: {}\".format(test_cost))\n",
    "    print(\"Test accuracy: {}\".format(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 100, training loss: 2.253172992125316\n",
      "Step 200, training loss: 2.100325195655345\n",
      "Step 300, training loss: 1.9737706802614237\n",
      "Step 400, training loss: 1.8961855549736484\n",
      "Step 500, training loss: 1.843433465359997\n",
      "Step 600, training loss: 1.8288526175755262\n",
      "Step 700, training loss: 1.7581627038417929\n",
      "Step 800, training loss: 1.7836182100101226\n",
      "Step 900, training loss: 1.764136539898768\n",
      "Step 1000, training loss: 1.6800498207387053\n",
      "Step 1100, training loss: 1.6835408784970007\n",
      "Step 1200, training loss: 1.6182474516372258\n",
      "Step 1300, training loss: 1.5944575005846007\n",
      "Step 1400, training loss: 1.5713009756287717\n",
      "Step 1500, training loss: 1.5531934641492364\n",
      "Step 1600, training loss: 1.536922642582774\n",
      "Step 1700, training loss: 1.4926557596758074\n",
      "Step 1800, training loss: 1.4814746398043157\n",
      "Step 1900, training loss: 1.4640033002828519\n",
      "Step 2000, training loss: 1.4590025017293484\n",
      "Step 2100, training loss: 1.463748985207479\n",
      "Step 2200, training loss: 1.4755525499033917\n",
      "Step 2300, training loss: 1.49542828963593\n",
      "Step 2400, training loss: 1.506491348014018\n",
      "Step 2500, training loss: 1.5786394266639074\n",
      "Step 2600, training loss: 1.5478815841643179\n",
      "Step 2700, training loss: 1.5724028033520518\n",
      "Step 2800, training loss: 1.645735971567443\n",
      "Step 2900, training loss: 1.5966398339516072\n",
      "Step 3000, training loss: 1.5965390954810637\n",
      "Step 3100, training loss: 1.572031647519534\n",
      "Step 3200, training loss: 1.539671443551256\n",
      "Step 3300, training loss: 1.51223298415147\n",
      "Step 3400, training loss: 1.4958027048243863\n",
      "Step 3500, training loss: 1.4697877055315864\n",
      "Step 3600, training loss: 1.4482226985444406\n",
      "Step 3700, training loss: 1.4229384890820012\n",
      "Step 3800, training loss: 1.4102800497137113\n",
      "Step 3900, training loss: 1.3969451589727104\n",
      "Step 4000, training loss: 1.3961774722369358\n",
      "Step 4100, training loss: 1.4045185562240072\n",
      "Step 4200, training loss: 1.4239804572515102\n",
      "Step 4300, training loss: 1.4278096235675939\n",
      "Step 4400, training loss: 1.462467662842851\n",
      "Step 4500, training loss: 1.495805279587662\n",
      "Step 4600, training loss: 1.5173571532498689\n",
      "Step 4700, training loss: 1.6921521509976398\n",
      "Step 4800, training loss: 1.5687560799846658\n",
      "Step 4900, training loss: 1.664498992731275\n",
      "Step 5000, training loss: 1.520888452037235\n",
      "Step 5100, training loss: 1.5428997634162898\n",
      "Step 5200, training loss: 1.5303460664874307\n",
      "Step 5300, training loss: 1.4628187417810914\n",
      "Step 5400, training loss: 1.4458813531590988\n",
      "Step 5500, training loss: 1.4334636381649846\n",
      "Step 5600, training loss: 1.4165836624954424\n",
      "Step 5700, training loss: 1.4014388390538213\n",
      "Step 5800, training loss: 1.383371288663986\n"
     ]
    }
   ],
   "source": [
    "# Best\n",
    "lmb = np.power(10, -2.325238114712273)\n",
    "layers = init_network()\n",
    "layers_trained, J_training, J_validation = mini_batch_GD(X, Y, GDparams, layers, lmb, validation, calculate_loss=True)\n",
    "test_cost = compute_cost(X_test, Y_test, layers_trained, lmb)\n",
    "test_acc = compute_accuracy(X_test, y_test, layers_trained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test cost:  1.5004219023178478\n",
      "Test accuracy:  0.5203\n"
     ]
    }
   ],
   "source": [
    "plt.figure(0)\n",
    "plt.ylabel(\"Cost\")\n",
    "plt.xlabel(\"Step\")\n",
    "plt.plot([step*100 for step in range(len(J_training))], J_training, label=\"Training\")\n",
    "plt.plot([step*100 for step in range(len(J_validation))], J_validation, label=\"Validation\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(\"Test cost: \", test_cost)\n",
    "print(\"Test accuracy: \", test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-bc5da7ab5566>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers_trained\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"W\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrot90\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'F'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"off\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not str"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(1)\n",
    "for i, j in enumerate(layers_trained[\"W\"]):\n",
    "    plt.subplot(2, 5, i+1)\n",
    "    plt.imshow(np.rot90(np.reshape((j - j.min()) / (j.max() - j.min()), (32, 32, 3), order='F'), k=3))\n",
    "    plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 3]\n",
      " [0 2 0]]\n"
     ]
    }
   ],
   "source": [
    "a = np.array([[1,-2,3], [-3, 2, -1]])\n",
    "print(np.maximum(a, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
